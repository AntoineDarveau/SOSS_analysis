{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports from standard packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract.overlap import TrpzOverlap\n",
    "from extract.throughput import ThroughputSOSS\n",
    "from extract.convolution import WebbKer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_flux = 1e2\n",
    "\n",
    "tilt = True\n",
    "\n",
    "# Main kwargs for simulation\n",
    "overlap_kwargs = {\"n_os\": 15,\n",
    "                  \"thresh\": 1e-8}\n",
    "# Convolution kwargs\n",
    "c_kwargs = {\"thresh\": 1e-6}\n",
    "\n",
    "# Output file\n",
    "output_file = f\"../Simulations/phoenix_teff_09000_scale_{scale_flux:.1e}_vsini_5.fits\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use interpolated PHOENIX spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/antoinedb/Documents/Doctorat/SOSS/\"\n",
    "model_file = \"Z-0.0-lte09000-4.00-0.0.PHOENIX-ACES-AGSS-COND-2011-n_os-15.npz\"\n",
    "spec_file = np.load(path+model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv, flux = spec_file[\"wave\"], spec_file[\"flux\"]\n",
    "# Multiplication by a fudge factor to get\n",
    "# a realistic number of counts on the detector\n",
    "flux *= scale_flux\n",
    "\n",
    "flux_interp = interp1d(wv, flux, kind=\"cubic\", bounds_error=False, fill_value=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of orders to consider in the extraction\n",
    "order_list = [1, 2]\n",
    "\n",
    "path = \"../jwst-mtl/SOSS/extract/Ref_files/\"\n",
    "\n",
    "#### Wavelength solution ####\n",
    "wave_maps = []\n",
    "wave_maps.append(fits.getdata(path + \"wavelengths_m1.fits\"))\n",
    "wave_maps.append(fits.getdata(path + \"wavelengths_m2.fits\"))\n",
    "\n",
    "#### Spatial profiles ####\n",
    "spat_pros = []\n",
    "spat_pros.append(fits.getdata(path + \"spat_profile_m1.fits\").squeeze())\n",
    "spat_pros.append(fits.getdata(path + \"spat_profile_m2.fits\").squeeze())\n",
    "\n",
    "# Convert data from fits files to float (fits precision is 1e-8)\n",
    "wave_maps = [wv.astype('float64') for wv in wave_maps]\n",
    "spat_pros = [p_ord.astype('float64') for p_ord in spat_pros]\n",
    "\n",
    "#### Throughputs ####\n",
    "thrpt_list = [ThroughputSOSS(order) for order in order_list]\n",
    "\n",
    "#### Convolution kernels ####\n",
    "ker_list = [WebbKer(wv_map) for wv_map in wave_maps]\n",
    "\n",
    "# Put all inputs from reference files in a list\n",
    "ref_files_args = [spat_pros, wave_maps, thrpt_list, ker_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read relevant files\n",
    "# wv_1 = fits.open(\"../jwst-mtl/SOSS/extract/Ref_files/wavelengths_m1.fits\")[0].data\n",
    "# wv_2 = fits.open(\"../jwst-mtl/SOSS/extract/Ref_files/wavelengths_m2.fits\")[0].data\n",
    "# P1 = fits.open(\"../jwst-mtl/SOSS/extract/Ref_files/spat_profile_m1.fits\")[0].data.squeeze()\n",
    "# P2 = fits.open(\"../jwst-mtl/SOSS/extract/Ref_files/spat_profile_m2.fits\")[0].data.squeeze()\n",
    "\n",
    "# # Convert to float (fits precision is 1e-8)\n",
    "# wv_1 = wv_1.astype(float)\n",
    "# wv_2 = wv_2.astype(float)\n",
    "# P1 = P1.astype(float)\n",
    "# P2 = P2.astype(float)\n",
    "\n",
    "# if not tilt:\n",
    "#     # Remove the tilt from wv maps\n",
    "#     wv_1 = np.tile(wv_1[50,:], (256, 1))\n",
    "#     wv_2 = np.tile(wv_2[50,:], (256, 1))\n",
    "    \n",
    "\n",
    "#### Initiate a simulation ####\n",
    "simu = TrpzOverlap(*ref_files_args, c_kwargs=c_kwargs, **overlap_kwargs)\n",
    "# simu = TrpzOverlap([P1,P2], [wv_1,wv_2], c_kwargs=c_kwargs, **overlap_kwargs)\n",
    "\n",
    "### Inject spectrum\n",
    "\n",
    "# Generate flux to inject\n",
    "flux = flux_interp(simu.lam_grid)\n",
    "\n",
    "# Init outputs\n",
    "out_ord = [{} for i in range(simu.n_ord)]\n",
    "out_full = {}\n",
    "\n",
    "# Inject order 1 and 2 separately (we don't want any contamination here)\n",
    "for i_ord in range(simu.n_ord):\n",
    "    out_ord[i_ord][\"data\"] = simu.rebuild(flux, orders=[i_ord])\n",
    "\n",
    "# Inject both orders (full)\n",
    "out_full[\"data\"] = simu.rebuild(flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation_utils import add_noise\n",
    "\n",
    "for out_dict in out_ord:\n",
    "    out_dict[\"noisy\"] = add_noise(out_dict[\"data\"])\n",
    "\n",
    "out_full[\"noisy\"] = add_noise(out_full[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save full simu and for each orders separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr = fits.Header()\n",
    "for key in overlap_kwargs:\n",
    "    hdr[key.upper()] = overlap_kwargs[key]\n",
    "    \n",
    "for key in c_kwargs:\n",
    "    hkey = \"C_\" + key.upper()\n",
    "    hdr[hkey] = c_kwargs[key]\n",
    "\n",
    "hdr[\"TILTED\"] = tilt\n",
    "\n",
    "# Save headers\n",
    "primary_hdu = fits.PrimaryHDU(header=hdr)\n",
    "hdul = fits.HDUList([primary_hdu])\n",
    "\n",
    "# Save flux\n",
    "col_list = []\n",
    "col_list.append(fits.Column(name=\"lam_grid\", array=simu.lam_grid, format=\"D\"))\n",
    "col_list.append(fits.Column(name='f_lam', array=flux, format='D'))\n",
    "table_hdu = fits.BinTableHDU.from_columns(col_list, name='FLUX')\n",
    "hdul.append(table_hdu)\n",
    "\n",
    "for i_ord, out in enumerate(out_ord):\n",
    "    name = f\"FLUX_C{simu.orders[i_ord]}\"\n",
    "    x = simu.lam_grid_c(i_ord)\n",
    "    y = simu.c_list[i_ord].dot(flux)\n",
    "    col_list = []\n",
    "    col_list.append(fits.Column(name='lam_grid', array=x, format='D'))\n",
    "    col_list.append(fits.Column(name='f_lam', array=y, format='D'))\n",
    "    table_hdu = fits.BinTableHDU.from_columns(col_list, name=name)\n",
    "    hdul.append(table_hdu)\n",
    "\n",
    "# Save detector simu\n",
    "hdul.append(fits.ImageHDU(out_full[\"data\"], name=\"FULL\"))\n",
    "hdul.append(fits.ImageHDU(out_full[\"noisy\"], name=\"FULL NOISY\"))\n",
    "for i_ord, out in enumerate(out_ord):\n",
    "    name = f\"ORD {simu.orders[i_ord]}\"\n",
    "    hdul.append(fits.ImageHDU(out[\"data\"], name=name))\n",
    "    hdul.append(fits.ImageHDU(out[\"noisy\"], name=name + \" NOISY\"))\n",
    "    \n",
    "# Write to file\n",
    "hdul.writeto(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
