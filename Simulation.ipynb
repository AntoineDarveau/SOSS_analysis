{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports from standard packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract.overlap import TrpzOverlap\n",
    "from extract.throughput import ThroughputSOSS\n",
    "from extract.convolution import WebbKer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WebbKer.file_frame = \"spectral_kernel_matrix_os_{}_width_{}pixels_cut.fits\"\n",
    "WebbKer.path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_flux = 1e2\n",
    "\n",
    "tilt = True\n",
    "\n",
    "# Main kwargs for simulation\n",
    "overlap_kwargs = {\"n_os\": 10,\n",
    "                  \"thresh\": 1e-8}\n",
    "# Convolution kwargs\n",
    "# c_kwargs = {\"thresh\": 1e-6}\n",
    "c_kwargs={'n_out':[5*10, 8*10], 'length':21*10+1}\n",
    "\n",
    "# Output file\n",
    "output_file = f\"../Simulations/phoenix_teff_09000_scale_{scale_flux:.1e}_vsini_5_cutker.fits\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use interpolated PHOENIX spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation_utils import load_simu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/Users/antoinedb/Documents/Doctorat/SOSS/\"\n",
    "# model_file = \"Z-0.0-lte09000-4.00-0.0.PHOENIX-ACES-AGSS-COND-2011-n_os-15.npz\"\n",
    "# spec_file = np.load(path+model_file)\n",
    "\n",
    "spec_file = load_simu(f\"../Simulations/phoenix_teff_09000_scale_{scale_flux:.1e}_vsini_5.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grid': array([0.55028933, 0.5503206 , 0.55035187, ..., 2.99896924, 2.99903714,\n",
       "        2.99910505]),\n",
       " 'f_k': array([4.72029320e+17, 4.71761943e+17, 4.71523937e+17, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'grid_c1': array([0.83615988, 0.83619105, 0.83622223, ..., 2.83632606, 2.83639357,\n",
       "        2.83646109]),\n",
       " 'f_c1': array([1.27513409e+17, 1.27493226e+17, 1.27473109e+17, ...,\n",
       "        2.24926315e+15, 2.24904694e+15, 2.24883060e+15]),\n",
       " 'grid_c2': array([0.5529112 , 0.55294192, 0.55297263, ..., 1.41168005, 1.4117111 ,\n",
       "        1.41176256]),\n",
       " 'f_c2': array([4.64368361e+17, 4.64324848e+17, 4.64286324e+17, ...,\n",
       "        2.77874001e+16, 2.77850474e+16, 2.77812351e+16]),\n",
       " 'data': array([[ 14.10512256,  -3.95967257,  10.52447484, ..., -14.13736113,\n",
       "         -20.94488784,  15.26676589],\n",
       "        [-17.11189848, -14.48966492,  -2.6145901 , ...,  -1.57250597,\n",
       "           6.15776183,  -0.287649  ],\n",
       "        [-23.88106705, -26.1715474 ,   0.77425164, ..., -12.09461067,\n",
       "         -14.47226874, -10.20277147],\n",
       "        ...,\n",
       "        [ 11.5055396 ,   8.72739604, -35.50451161, ...,   9.15307088,\n",
       "          -6.69575933,   7.82393428],\n",
       "        [ -6.7708633 ,  -1.63006998,  -5.85568796, ...,  -0.2049306 ,\n",
       "         -33.31860831, -32.24496944],\n",
       "        [-23.77788793,  31.20743965,  46.52620624, ...,   7.17086185,\n",
       "         -15.50301379, -18.08598337]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wv, flux = spec_file[\"wave\"], spec_file[\"flux\"]\n",
    "wv, flux = spec_file[\"grid\"], spec_file[\"f_k\"]\n",
    "# # Multiplication by a fudge factor to get\n",
    "# # a realistic number of counts on the detector\n",
    "# flux *= scale_flux\n",
    "\n",
    "flux_interp = interp1d(wv, flux, kind=\"cubic\", bounds_error=False, fill_value=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract.convolution import fwhm2sigma, gaussians\n",
    "\n",
    "class GaussKer:\n",
    "\n",
    "    def __init__(self, grid, res, bounds_error=False,\n",
    "                 fill_value=\"extrapolate\", **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        grid : 1d array\n",
    "            Grid used to define the kernels\n",
    "        fwhm: ...\n",
    "            ...\n",
    "        bounds_error, fill_value and kwargs:\n",
    "            `interp1d` kwargs used to get FWHM as a function of the grid.\n",
    "        \"\"\"\n",
    "        fwhm = grid / res\n",
    "        \n",
    "        # What we really want is sigma, not FWHM\n",
    "        sig = fwhm2sigma(fwhm)\n",
    "\n",
    "        # Now put sigma as a function of the grid\n",
    "        sig = interp1d(grid, sig, bounds_error=bounds_error,\n",
    "                       fill_value=fill_value, **kwargs)\n",
    "\n",
    "        self.fct_sig = sig\n",
    "\n",
    "    def __call__(self, x, x0):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: 1d array\n",
    "            position where the kernel is evaluated\n",
    "        x0: 1d array (same shape as x)\n",
    "            position of the kernel center for each x.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Value of the gaussian kernel for each sets of (x, x0)\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the sigma of each gaussians\n",
    "        sig = self.fct_sig(x0)\n",
    "\n",
    "        return gaussians(x, x0, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of orders to consider in the extraction\n",
    "order_list = [1, 2]\n",
    "\n",
    "path = \"../jwst-mtl/SOSS/extract/Ref_files/\"\n",
    "\n",
    "#### Wavelength solution ####\n",
    "wave_maps = []\n",
    "wave_maps.append(fits.getdata(path + \"wavelengths_m1.fits\"))\n",
    "wave_maps.append(fits.getdata(path + \"wavelengths_m2.fits\"))\n",
    "\n",
    "if not tilt:\n",
    "    # Remove the tilt from wv maps\n",
    "    wave_maps[0] = np.tile(wave_maps[0][50,:], (256, 1))\n",
    "    wave_maps[1] = np.tile(wave_maps[1][50,:], (256, 1))\n",
    "\n",
    "#### Spatial profiles ####\n",
    "spat_pros = []\n",
    "spat_pros.append(fits.getdata(path + \"spat_profile_m1.fits\").squeeze())\n",
    "spat_pros.append(fits.getdata(path + \"spat_profile_m2.fits\").squeeze())\n",
    "\n",
    "# Convert data from fits files to float (fits precision is 1e-8)\n",
    "wave_maps = [wv.astype('float64') for wv in wave_maps]\n",
    "spat_pros = [p_ord.astype('float64') for p_ord in spat_pros]\n",
    "\n",
    "#### Throughputs ####\n",
    "thrpt_list = [ThroughputSOSS(order) for order in order_list]\n",
    "\n",
    "#### Convolution kernels ####\n",
    "ker_list = [WebbKer(wv_map) for wv_map in wave_maps]\n",
    "# ker_list = [GaussKer(wv, res) for res in [2000, 900]]\n",
    "\n",
    "# Put all inputs from reference files in a list\n",
    "ref_files_args = [spat_pros, wave_maps, thrpt_list, ker_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read relevant files\n",
    "# wv_1 = fits.open(\"../jwst-mtl/SOSS/extract/Ref_files/wavelengths_m1.fits\")[0].data\n",
    "# wv_2 = fits.open(\"../jwst-mtl/SOSS/extract/Ref_files/wavelengths_m2.fits\")[0].data\n",
    "# P1 = fits.open(\"../jwst-mtl/SOSS/extract/Ref_files/spat_profile_m1.fits\")[0].data.squeeze()\n",
    "# P2 = fits.open(\"../jwst-mtl/SOSS/extract/Ref_files/spat_profile_m2.fits\")[0].data.squeeze()\n",
    "\n",
    "# # Convert to float (fits precision is 1e-8)\n",
    "# wv_1 = wv_1.astype(float)\n",
    "# wv_2 = wv_2.astype(float)\n",
    "# P1 = P1.astype(float)\n",
    "# P2 = P2.astype(float)\n",
    "\n",
    "# if not tilt:\n",
    "#     # Remove the tilt from wv maps\n",
    "#     wv_1 = np.tile(wv_1[50,:], (256, 1))\n",
    "#     wv_2 = np.tile(wv_2[50,:], (256, 1))\n",
    "    \n",
    "\n",
    "#### Initiate a simulation ####\n",
    "simu = TrpzOverlap(*ref_files_args, c_kwargs=c_kwargs, **overlap_kwargs)\n",
    "# simu = TrpzOverlap([P1,P2], [wv_1,wv_2], c_kwargs=c_kwargs, **overlap_kwargs)\n",
    "\n",
    "### Inject spectrum\n",
    "\n",
    "# Generate flux to inject\n",
    "flux = flux_interp(simu.lam_grid)\n",
    "\n",
    "# Init outputs\n",
    "out_ord = [{} for i in range(simu.n_ord)]\n",
    "out_full = {}\n",
    "\n",
    "# Inject order 1 and 2 separately (we don't want any contamination here)\n",
    "for i_ord in range(simu.n_ord):\n",
    "    out_ord[i_ord][\"data\"] = simu.rebuild(flux, orders=[i_ord])\n",
    "\n",
    "# Inject both orders (full)\n",
    "out_full[\"data\"] = simu.rebuild(flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation_utils import add_noise\n",
    "\n",
    "for out_dict in out_ord:\n",
    "    out_dict[\"noisy\"] = add_noise(out_dict[\"data\"])\n",
    "\n",
    "out_full[\"noisy\"] = add_noise(out_full[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save full simu and for each orders separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr = fits.Header()\n",
    "for key in overlap_kwargs:\n",
    "    hdr[key.upper()] = overlap_kwargs[key]\n",
    "    \n",
    "for key in c_kwargs:\n",
    "    hkey = \"C_\" + key.upper()\n",
    "    hdr[hkey] = str(c_kwargs[key])\n",
    "\n",
    "hdr[\"TILTED\"] = tilt\n",
    "\n",
    "# Save headers\n",
    "primary_hdu = fits.PrimaryHDU(header=hdr)\n",
    "hdul = fits.HDUList([primary_hdu])\n",
    "\n",
    "# Save flux\n",
    "col_list = []\n",
    "col_list.append(fits.Column(name=\"lam_grid\", array=simu.lam_grid, format=\"D\"))\n",
    "col_list.append(fits.Column(name='f_lam', array=flux, format='D'))\n",
    "table_hdu = fits.BinTableHDU.from_columns(col_list, name='FLUX')\n",
    "hdul.append(table_hdu)\n",
    "\n",
    "for i_ord, out in enumerate(out_ord):\n",
    "    name = f\"FLUX_C{simu.orders[i_ord]}\"\n",
    "    x = simu.lam_grid_c(i_ord)\n",
    "    y = simu.c_list[i_ord].dot(flux)\n",
    "    col_list = []\n",
    "    col_list.append(fits.Column(name='lam_grid', array=x, format='D'))\n",
    "    col_list.append(fits.Column(name='f_lam', array=y, format='D'))\n",
    "    table_hdu = fits.BinTableHDU.from_columns(col_list, name=name)\n",
    "    hdul.append(table_hdu)\n",
    "\n",
    "# Save detector simu\n",
    "hdul.append(fits.ImageHDU(out_full[\"data\"], name=\"FULL\"))\n",
    "hdul.append(fits.ImageHDU(out_full[\"noisy\"], name=\"FULL NOISY\"))\n",
    "for i_ord, out in enumerate(out_ord):\n",
    "    name = f\"ORD {simu.orders[i_ord]}\"\n",
    "    hdul.append(fits.ImageHDU(out[\"data\"], name=name))\n",
    "    hdul.append(fits.ImageHDU(out[\"noisy\"], name=name + \" NOISY\"))\n",
    "    \n",
    "# Write to file\n",
    "hdul.writeto(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
